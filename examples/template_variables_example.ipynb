{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f560db8",
   "metadata": {},
   "source": [
    "# Template Variables Example\n",
    "\n",
    "**Example: Using Template Variables with Pipeline**\n",
    "\n",
    "\n",
    "Demonstrates how to use Jinja2-style template variables in SQL queries.\n",
    "This is useful for:\n",
    "- Multi-environment pipelines (dev, staging, prod)\n",
    "- Parameterized table names\n",
    "- dbt-style ref() functions\n",
    "- Airflow macro substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128091c2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f6f7a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.111497Z",
     "iopub.status.busy": "2025-12-30T19:34:04.111339Z",
     "iopub.status.idle": "2025-12-30T19:34:04.215551Z",
     "shell.execute_reply": "2025-12-30T19:34:04.215179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'user_id' in expression for 'user_id'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'username' in expression for 'username'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Example 1: Multi-Environment Pipeline\n",
      "============================================================\n",
      "\n",
      "Production Tables:\n",
      "  - prod_staging.orders\n",
      "  - raw.orders\n",
      "  - prod_analytics.customer_metrics\n",
      "\n",
      "Development Tables:\n",
      "  - dev_staging.orders\n",
      "  - raw.orders\n",
      "  - dev_analytics.customer_metrics\n",
      "\n",
      "============================================================\n",
      "Example 2: Project-Based Configuration\n",
      "============================================================\n",
      "\n",
      "Generated Tables:\n",
      "  - my_company.staging.user_data\n",
      "  - my_company.raw.users\n",
      "  - my_company.analytics.user_summary\n",
      "  - my_company.raw.activities\n",
      "\n",
      "============================================================\n",
      "Example 3: Nested Variables (config.property)\n",
      "============================================================\n",
      "\n",
      "Generated Tables:\n",
      "  - data_platform.staging_staging.orders\n",
      "  - external_db.raw_us_central.orders\n",
      "\n",
      "============================================================\n",
      "Example 4: YAML-style Configuration\n",
      "============================================================\n",
      "\n",
      "YAML Config:\n",
      "config:\n",
      "  dataset: customer_data\n",
      "  region: us-central1\n",
      "  start_date: 2025-01-01\n",
      "env: production\n",
      "project: analytics_pipeline\n",
      "\n",
      "Generated Tables:\n",
      "  - analytics_pipeline.production_staging.customers\n",
      "  - source.customers\n",
      "\n",
      "============================================================\n",
      "Example 5: Column Lineage Tracing with Templates\n",
      "============================================================\n",
      "\n",
      "Tracing column lineage for: prod_analytics.customer_metrics.total_revenue\n",
      "\n",
      "Source columns (1):\n",
      "  - raw.orders.amount (base_column)\n",
      "\n",
      "============================================================\n",
      "Example 6: Without Template Context (SQL validation only)\n",
      "============================================================\n",
      "\n",
      "Tables (template syntax preserved):\n",
      "  - {{env}}_staging.orders\n",
      "  - raw.orders\n",
      "  - {{env}}_analytics.customer_metrics\n",
      "\n",
      "Note: Template syntax like {{env}} is preserved when no template_context is provided.\n",
      "This is useful for SQL validation before deployment.\n",
      "\n",
      "============================================================\n",
      "Example 7: dbt-style ref() Functions\n",
      "============================================================\n",
      "\n",
      "Note: For full dbt integration, use dbt's compiled SQL output\n",
      "or implement a custom Jinja2 function resolver.\n",
      "\n",
      "============================================================\n",
      "Summary: Template Variables are Powerful!\n",
      "============================================================\n",
      "\n",
      "âœ… Use Cases:\n",
      "  - Multi-environment deployments (dev/staging/prod)\n",
      "  - Parameterized table names across regions/projects\n",
      "  - dbt integration (via compiled SQL)\n",
      "  - Airflow macro substitution\n",
      "  - CI/CD pipeline configuration\n",
      "\n",
      "âœ… Supported Syntaxes:\n",
      "  - Jinja2: {{ variable }}\n",
      "  - Nested: {{ config.property }}\n",
      "  - Functions: {{ ref('table') }} (with custom resolution)\n",
      "\n",
      "âœ… Input Formats:\n",
      "  - Python dict: {\"env\": \"prod\"}\n",
      "  - YAML: env: prod\n",
      "  - JSON: {\"env\": \"prod\"}\n",
      "\n",
      "ðŸ’¡ Best Practice:\n",
      "  - Define template variables in separate config files (YAML/JSON)\n",
      "  - Use consistent naming conventions (env, project, region)\n",
      "  - Document required variables in README\n",
      "  - Validate templates without context for syntax checking\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "from clgraph import Pipeline\n",
    "\n",
    "# Example 1: Multi-Environment Pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Multi-Environment Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# SQL with environment placeholders\n",
    "queries_with_env = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        order_date\n",
    "    FROM raw.orders\n",
    "    WHERE status = 'completed'\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_analytics.customer_metrics AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(amount) as total_revenue,\n",
    "        AVG(amount) as avg_order_value\n",
    "    FROM {{env}}_staging.orders\n",
    "    GROUP BY customer_id\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "# Build pipeline for PRODUCTION environment\n",
    "prod_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"prod\"}\n",
    ")\n",
    "\n",
    "print(\"\\nProduction Tables:\")\n",
    "for table in prod_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Build pipeline for DEVELOPMENT environment\n",
    "dev_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"dev\"}\n",
    ")\n",
    "\n",
    "print(\"\\nDevelopment Tables:\")\n",
    "for table in dev_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 2: Project-Based Configuration\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 2: Project-Based Configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "queries_with_project = {\n",
    "    \"staging\": \"\"\"\n",
    "        CREATE TABLE {{project}}.staging.user_data AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            email,\n",
    "            created_at\n",
    "        FROM {{project}}.raw.users\n",
    "    \"\"\",\n",
    "    \"analytics\": \"\"\"\n",
    "        CREATE TABLE {{project}}.analytics.user_summary AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            COUNT(*) as activity_count\n",
    "        FROM {{project}}.staging.user_data\n",
    "        JOIN {{project}}.raw.activities USING (user_id)\n",
    "        GROUP BY user_id, username\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "pipeline = Pipeline.from_dict(\n",
    "    queries_with_project, dialect=\"bigquery\", template_context={\"project\": \"my_company\"}\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 3: Nested Variables\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 3: Nested Variables (config.property)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "queries_nested = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{config.project}}.{{config.env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount\n",
    "    FROM {{config.source_db}}.raw_{{config.region}}.orders\n",
    "    WHERE created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_nested = Pipeline.from_sql_list(\n",
    "    queries_nested,\n",
    "    dialect=\"bigquery\",\n",
    "    template_context={\n",
    "        \"config\": {\n",
    "            \"project\": \"data_platform\",\n",
    "            \"env\": \"staging\",\n",
    "            \"source_db\": \"external_db\",\n",
    "            \"region\": \"us_central\",\n",
    "            \"start_date\": \"2025-01-01\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline_nested.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 4: YAML Configuration (as you'd use in CLI)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 4: YAML-style Configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# YAML config file content\n",
    "yaml_config = \"\"\"\n",
    "env: production\n",
    "project: analytics_pipeline\n",
    "config:\n",
    "  region: us-central1\n",
    "  dataset: customer_data\n",
    "  start_date: 2025-01-01\n",
    "\"\"\"\n",
    "\n",
    "# Parse YAML\n",
    "template_context = yaml.safe_load(yaml_config)\n",
    "\n",
    "queries_yaml = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{project}}.{{env}}_staging.customers AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        region\n",
    "    FROM source.customers\n",
    "    WHERE region = '{{config.region}}'\n",
    "    AND created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_yaml = Pipeline.from_sql_list(\n",
    "    queries_yaml, dialect=\"bigquery\", template_context=template_context\n",
    ")\n",
    "\n",
    "print(\"\\nYAML Config:\")\n",
    "print(yaml.dump(template_context, default_flow_style=False))\n",
    "\n",
    "print(\"Generated Tables:\")\n",
    "for table in pipeline_yaml.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 5: Column Lineage with Templates\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 5: Column Lineage Tracing with Templates\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use the production pipeline from Example 1\n",
    "print(\"\\nTracing column lineage for: prod_analytics.customer_metrics.total_revenue\")\n",
    "\n",
    "# Trace column backward to sources\n",
    "sources = prod_pipeline.trace_column_backward(\"prod_analytics.customer_metrics\", \"total_revenue\")\n",
    "\n",
    "print(f\"\\nSource columns ({len(sources)}):\")\n",
    "for source in sources:\n",
    "    print(f\"  - {source.table_name}.{source.column_name} ({source.node_type})\")\n",
    "\n",
    "# Example 6: Without Template Context (preserves template syntax)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 6: Without Template Context (SQL validation only)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pipeline_no_context = Pipeline.from_sql_list(\n",
    "    queries_with_env,\n",
    "    dialect=\"bigquery\",\n",
    "    # NO template_context provided\n",
    ")\n",
    "\n",
    "print(\"\\nTables (template syntax preserved):\")\n",
    "for table in pipeline_no_context.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "print(\"\\nNote: Template syntax like {{env}} is preserved when no template_context is provided.\")\n",
    "print(\"This is useful for SQL validation before deployment.\")\n",
    "\n",
    "# Example 7: dbt-style ref() functions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 7: dbt-style ref() Functions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dbt_queries = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{ ref('staging_orders') }} AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount\n",
    "    FROM {{ ref('raw_orders') }}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "# Custom function to resolve dbt ref()\n",
    "def resolve_dbt_ref(table_name):\n",
    "    return f\"my_project.{table_name}\"\n",
    "\n",
    "\n",
    "# Manually resolve refs (for demonstration)\n",
    "# In practice, you'd use dbt's built-in templating\n",
    "pipeline_dbt = Pipeline.from_sql_list(\n",
    "    dbt_queries,\n",
    "    dialect=\"bigquery\",\n",
    "    template_context={\n",
    "        \"ref\": lambda name: f\"my_project.{name}\"  # Note: This won't work with Jinja2, just for demo\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nNote: For full dbt integration, use dbt's compiled SQL output\")\n",
    "print(\"or implement a custom Jinja2 function resolver.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Template Variables are Powerful!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ… Use Cases:\n",
    "  - Multi-environment deployments (dev/staging/prod)\n",
    "  - Parameterized table names across regions/projects\n",
    "  - dbt integration (via compiled SQL)\n",
    "  - Airflow macro substitution\n",
    "  - CI/CD pipeline configuration\n",
    "\n",
    "âœ… Supported Syntaxes:\n",
    "  - Jinja2: {{ variable }}\n",
    "  - Nested: {{ config.property }}\n",
    "  - Functions: {{ ref('table') }} (with custom resolution)\n",
    "\n",
    "âœ… Input Formats:\n",
    "  - Python dict: {\"env\": \"prod\"}\n",
    "  - YAML: env: prod\n",
    "  - JSON: {\"env\": \"prod\"}\n",
    "\n",
    "ðŸ’¡ Best Practice:\n",
    "  - Define template variables in separate config files (YAML/JSON)\n",
    "  - Use consistent naming conventions (env, project, region)\n",
    "  - Document required variables in README\n",
    "  - Validate templates without context for syntax checking\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e446c27",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3a5215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.216931Z",
     "iopub.status.busy": "2025-12-30T19:34:04.216802Z",
     "iopub.status.idle": "2025-12-30T19:34:04.218649Z",
     "shell.execute_reply": "2025-12-30T19:34:04.218218Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from clgraph import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941219c6",
   "metadata": {},
   "source": [
    "### Example 1: Multi-Environment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe104f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.219709Z",
     "iopub.status.busy": "2025-12-30T19:34:04.219631Z",
     "iopub.status.idle": "2025-12-30T19:34:04.229097Z",
     "shell.execute_reply": "2025-12-30T19:34:04.228782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Multi-Environment Pipeline\n",
      "\n",
      "Production Tables:\n",
      "  - prod_staging.orders\n",
      "  - raw.orders\n",
      "  - prod_analytics.customer_metrics\n",
      "\n",
      "Development Tables:\n",
      "  - dev_staging.orders\n",
      "  - raw.orders\n",
      "  - dev_analytics.customer_metrics\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 1: Multi-Environment Pipeline\")\n",
    "\n",
    "# SQL with environment placeholders\n",
    "queries_with_env = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        order_date\n",
    "    FROM raw.orders\n",
    "    WHERE status = 'completed'\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_analytics.customer_metrics AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(amount) as total_revenue,\n",
    "        AVG(amount) as avg_order_value\n",
    "    FROM {{env}}_staging.orders\n",
    "    GROUP BY customer_id\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "# Build pipeline for PRODUCTION environment\n",
    "prod_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"prod\"}\n",
    ")\n",
    "\n",
    "print(\"\\nProduction Tables:\")\n",
    "for table in prod_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Build pipeline for DEVELOPMENT environment\n",
    "dev_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"dev\"}\n",
    ")\n",
    "\n",
    "print(\"\\nDevelopment Tables:\")\n",
    "for table in dev_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4525339",
   "metadata": {},
   "source": [
    "### Example 2: Project-Based Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be3ac20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.230147Z",
     "iopub.status.busy": "2025-12-30T19:34:04.230079Z",
     "iopub.status.idle": "2025-12-30T19:34:04.236004Z",
     "shell.execute_reply": "2025-12-30T19:34:04.235740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'user_id' in expression for 'user_id'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'username' in expression for 'username'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2: Project-Based Configuration\n",
      "\n",
      "Generated Tables:\n",
      "  - my_company.staging.user_data\n",
      "  - my_company.raw.users\n",
      "  - my_company.analytics.user_summary\n",
      "  - my_company.raw.activities\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 2: Project-Based Configuration\")\n",
    "\n",
    "queries_with_project = {\n",
    "    \"staging\": \"\"\"\n",
    "        CREATE TABLE {{project}}.staging.user_data AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            email,\n",
    "            created_at\n",
    "        FROM {{project}}.raw.users\n",
    "    \"\"\",\n",
    "    \"analytics\": \"\"\"\n",
    "        CREATE TABLE {{project}}.analytics.user_summary AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            COUNT(*) as activity_count\n",
    "        FROM {{project}}.staging.user_data\n",
    "        JOIN {{project}}.raw.activities USING (user_id)\n",
    "        GROUP BY user_id, username\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "pipeline = Pipeline.from_dict(\n",
    "    queries_with_project, dialect=\"bigquery\", template_context={\"project\": \"my_company\"}\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd136b",
   "metadata": {},
   "source": [
    "### Example 3: Nested Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea242d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.237190Z",
     "iopub.status.busy": "2025-12-30T19:34:04.237102Z",
     "iopub.status.idle": "2025-12-30T19:34:04.241293Z",
     "shell.execute_reply": "2025-12-30T19:34:04.240980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3: Nested Variables (config.property)\n",
      "\n",
      "Generated Tables:\n",
      "  - data_platform.staging_staging.orders\n",
      "  - external_db.raw_us_central.orders\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 3: Nested Variables (config.property)\")\n",
    "\n",
    "queries_nested = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{config.project}}.{{config.env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount\n",
    "    FROM {{config.source_db}}.raw_{{config.region}}.orders\n",
    "    WHERE created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_nested = Pipeline.from_sql_list(\n",
    "    queries_nested,\n",
    "    dialect=\"bigquery\",\n",
    "    template_context={\n",
    "        \"config\": {\n",
    "            \"project\": \"data_platform\",\n",
    "            \"env\": \"staging\",\n",
    "            \"source_db\": \"external_db\",\n",
    "            \"region\": \"us_central\",\n",
    "            \"start_date\": \"2025-01-01\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline_nested.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f76de2",
   "metadata": {},
   "source": [
    "### Example 4: YAML Configuration (as you'd use in CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebbb946e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.242283Z",
     "iopub.status.busy": "2025-12-30T19:34:04.242216Z",
     "iopub.status.idle": "2025-12-30T19:34:04.247092Z",
     "shell.execute_reply": "2025-12-30T19:34:04.246741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 4: YAML-style Configuration\n",
      "\n",
      "YAML Config:\n",
      "config:\n",
      "  dataset: customer_data\n",
      "  region: us-central1\n",
      "  start_date: 2025-01-01\n",
      "env: production\n",
      "project: analytics_pipeline\n",
      "\n",
      "Generated Tables:\n",
      "  - analytics_pipeline.production_staging.customers\n",
      "  - source.customers\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 4: YAML-style Configuration\")\n",
    "\n",
    "# YAML config file content\n",
    "yaml_config = \"\"\"\n",
    "env: production\n",
    "project: analytics_pipeline\n",
    "config:\n",
    "  region: us-central1\n",
    "  dataset: customer_data\n",
    "  start_date: 2025-01-01\n",
    "\"\"\"\n",
    "\n",
    "# Parse YAML\n",
    "template_context = yaml.safe_load(yaml_config)\n",
    "\n",
    "queries_yaml = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{project}}.{{env}}_staging.customers AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        region\n",
    "    FROM source.customers\n",
    "    WHERE region = '{{config.region}}'\n",
    "    AND created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_yaml = Pipeline.from_sql_list(\n",
    "    queries_yaml, dialect=\"bigquery\", template_context=template_context\n",
    ")\n",
    "\n",
    "print(\"\\nYAML Config:\")\n",
    "print(yaml.dump(template_context, default_flow_style=False))\n",
    "\n",
    "print(\"Generated Tables:\")\n",
    "for table in pipeline_yaml.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12788f18",
   "metadata": {},
   "source": [
    "### Example 5: Column Lineage with Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c2d885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.248241Z",
     "iopub.status.busy": "2025-12-30T19:34:04.248156Z",
     "iopub.status.idle": "2025-12-30T19:34:04.251988Z",
     "shell.execute_reply": "2025-12-30T19:34:04.251635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 5: Column Lineage Tracing with Templates\n",
      "\n",
      "Tracing column lineage for: prod_analytics.customer_metrics.total_revenue\n",
      "\n",
      "Source columns (1):\n",
      "  - raw.orders.amount (base_column)\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 5: Column Lineage Tracing with Templates\")\n",
    "\n",
    "# Use the production pipeline from Example 1\n",
    "print(\"\\nTracing column lineage for: prod_analytics.customer_metrics.total_revenue\")\n",
    "\n",
    "# Trace column backward to sources\n",
    "sources = prod_pipeline.trace_column_backward(\"prod_analytics.customer_metrics\", \"total_revenue\")\n",
    "\n",
    "print(f\"\\nSource columns ({len(sources)}):\")\n",
    "for source in sources:\n",
    "    print(f\"  - {source.table_name}.{source.column_name} ({source.node_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28259b50",
   "metadata": {},
   "source": [
    "### Example 6: Without Template Context (preserves template syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc39482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.252947Z",
     "iopub.status.busy": "2025-12-30T19:34:04.252875Z",
     "iopub.status.idle": "2025-12-30T19:34:04.257453Z",
     "shell.execute_reply": "2025-12-30T19:34:04.257114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 6: Without Template Context (SQL validation only)\n",
      "\n",
      "Tables (template syntax preserved):\n",
      "  - {{env}}_staging.orders\n",
      "  - raw.orders\n",
      "  - {{env}}_analytics.customer_metrics\n",
      "\n",
      "Note: Template syntax like {{env}} is preserved when no template_context is provided.\n",
      "This is useful for SQL validation before deployment.\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 6: Without Template Context (SQL validation only)\")\n",
    "\n",
    "pipeline_no_context = Pipeline.from_sql_list(\n",
    "    queries_with_env,\n",
    "    dialect=\"bigquery\",\n",
    "    # NO template_context provided\n",
    ")\n",
    "\n",
    "print(\"\\nTables (template syntax preserved):\")\n",
    "for table in pipeline_no_context.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "print(\"\\nNote: Template syntax like {{env}} is preserved when no template_context is provided.\")\n",
    "print(\"This is useful for SQL validation before deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60025c53",
   "metadata": {},
   "source": [
    "### Example 7: dbt-style ref() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b563b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:04.258518Z",
     "iopub.status.busy": "2025-12-30T19:34:04.258444Z",
     "iopub.status.idle": "2025-12-30T19:34:04.262265Z",
     "shell.execute_reply": "2025-12-30T19:34:04.261906Z"
    }
   },
   "outputs": [],
   "source": "print(\"Example 7: dbt-style ref() Functions\")\n\ndbt_queries = [\n    \"\"\"\n    CREATE TABLE {{ ref('staging_orders') }} AS\n    SELECT\n        order_id,\n        customer_id,\n        amount\n    FROM {{ ref('raw_orders') }}\n    \"\"\"\n]\n\n\n# Note: resolve_dbt_ref is already defined in a previous cell\n# Manually resolve refs (for demonstration)\n# In practice, you'd use dbt's built-in templating\npipeline_dbt = Pipeline.from_sql_list(\n    dbt_queries,\n    dialect=\"bigquery\",\n    template_context={\n        \"ref\": lambda name: f\"my_project.{name}\"  # Note: This won't work with Jinja2, just for demo\n    },\n)\n\nprint(\"\\nNote: For full dbt integration, use dbt's compiled SQL output\")\nprint(\"or implement a custom Jinja2 function resolver.\")\n\nprint(\"Summary: Template Variables are Powerful!\")\nprint(\"\"\"\nâœ… Use Cases:\n  - Multi-environment deployments (dev/staging/prod)\n  - Parameterized table names across regions/projects\n  - dbt integration (via compiled SQL)\n  - Airflow macro substitution\n  - CI/CD pipeline configuration\n\nâœ… Supported Syntaxes:\n  - Jinja2: {{ variable }}\n  - Nested: {{ config.property }}\n  - Functions: {{ ref('table') }} (with custom resolution)\n\nâœ… Input Formats:\n  - Python dict: {\"env\": \"prod\"}\n  - YAML: env: prod\n  - JSON: {\"env\": \"prod\"}\n\nðŸ’¡ Best Practice:\n  - Define template variables in separate config files (YAML/JSON)\n  - Use consistent naming conventions (env, project, region)\n  - Document required variables in README\n  - Validate templates without context for syntax checking\n\"\"\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}