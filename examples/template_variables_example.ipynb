{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f560db8",
   "metadata": {},
   "source": [
    "# Template Variables Example\n",
    "\n",
    "**Example: Using Template Variables with Pipeline**\n",
    "\n",
    "\n",
    "Demonstrates how to use Jinja2-style template variables in SQL queries.\n",
    "This is useful for:\n",
    "- Multi-environment pipelines (dev, staging, prod)\n",
    "- Parameterized table names\n",
    "- dbt-style ref() functions\n",
    "- Airflow macro substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128091c2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f6f7a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.647696Z",
     "iopub.status.busy": "2025-12-30T20:02:28.647367Z",
     "iopub.status.idle": "2025-12-30T20:02:28.758974Z",
     "shell.execute_reply": "2025-12-30T20:02:28.758467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'user_id' in expression for 'user_id'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'username' in expression for 'username'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Example 1: Multi-Environment Pipeline\n",
      "============================================================\n",
      "\n",
      "Production Tables:\n",
      "  - prod_staging.orders\n",
      "  - raw.orders\n",
      "  - prod_analytics.customer_metrics\n",
      "\n",
      "Development Tables:\n",
      "  - dev_staging.orders\n",
      "  - raw.orders\n",
      "  - dev_analytics.customer_metrics\n",
      "\n",
      "============================================================\n",
      "Example 2: Project-Based Configuration\n",
      "============================================================\n",
      "\n",
      "Generated Tables:\n",
      "  - my_company.staging.user_data\n",
      "  - my_company.raw.users\n",
      "  - my_company.analytics.user_summary\n",
      "  - my_company.raw.activities\n",
      "\n",
      "============================================================\n",
      "Example 3: Nested Variables (config.property)\n",
      "============================================================\n",
      "\n",
      "Generated Tables:\n",
      "  - data_platform.staging_staging.orders\n",
      "  - external_db.raw_us_central.orders\n",
      "\n",
      "============================================================\n",
      "Example 4: YAML-style Configuration\n",
      "============================================================\n",
      "\n",
      "YAML Config:\n",
      "config:\n",
      "  dataset: customer_data\n",
      "  region: us-central1\n",
      "  start_date: 2025-01-01\n",
      "env: production\n",
      "project: analytics_pipeline\n",
      "\n",
      "Generated Tables:\n",
      "  - analytics_pipeline.production_staging.customers\n",
      "  - source.customers\n",
      "\n",
      "============================================================\n",
      "Example 5: Column Lineage Tracing with Templates\n",
      "============================================================\n",
      "\n",
      "Tracing column lineage for: prod_analytics.customer_metrics.total_revenue\n",
      "\n",
      "Source columns (1):\n",
      "  - raw.orders.amount (base_column)\n",
      "\n",
      "============================================================\n",
      "Example 6: Without Template Context (SQL validation only)\n",
      "============================================================\n",
      "\n",
      "Tables (template syntax preserved):\n",
      "  - {{env}}_staging.orders\n",
      "  - raw.orders\n",
      "  - {{env}}_analytics.customer_metrics\n",
      "\n",
      "Note: Template syntax like {{env}} is preserved when no template_context is provided.\n",
      "This is useful for SQL validation before deployment.\n",
      "\n",
      "============================================================\n",
      "Example 7: dbt-style ref() Functions\n",
      "============================================================\n",
      "\n",
      "Note: For full dbt integration, use dbt's compiled SQL output\n",
      "or implement a custom Jinja2 function resolver.\n",
      "\n",
      "============================================================\n",
      "Summary: Template Variables are Powerful!\n",
      "============================================================\n",
      "\n",
      "âœ… Use Cases:\n",
      "  - Multi-environment deployments (dev/staging/prod)\n",
      "  - Parameterized table names across regions/projects\n",
      "  - dbt integration (via compiled SQL)\n",
      "  - Airflow macro substitution\n",
      "  - CI/CD pipeline configuration\n",
      "\n",
      "âœ… Supported Syntaxes:\n",
      "  - Jinja2: {{ variable }}\n",
      "  - Nested: {{ config.property }}\n",
      "  - Functions: {{ ref('table') }} (with custom resolution)\n",
      "\n",
      "âœ… Input Formats:\n",
      "  - Python dict: {\"env\": \"prod\"}\n",
      "  - YAML: env: prod\n",
      "  - JSON: {\"env\": \"prod\"}\n",
      "\n",
      "ðŸ’¡ Best Practice:\n",
      "  - Define template variables in separate config files (YAML/JSON)\n",
      "  - Use consistent naming conventions (env, project, region)\n",
      "  - Document required variables in README\n",
      "  - Validate templates without context for syntax checking\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "from clgraph import Pipeline\n",
    "\n",
    "# Example 1: Multi-Environment Pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Multi-Environment Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# SQL with environment placeholders\n",
    "queries_with_env = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        order_date\n",
    "    FROM raw.orders\n",
    "    WHERE status = 'completed'\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_analytics.customer_metrics AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(amount) as total_revenue,\n",
    "        AVG(amount) as avg_order_value\n",
    "    FROM {{env}}_staging.orders\n",
    "    GROUP BY customer_id\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "# Build pipeline for PRODUCTION environment\n",
    "prod_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"prod\"}\n",
    ")\n",
    "\n",
    "print(\"\\nProduction Tables:\")\n",
    "for table in prod_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Build pipeline for DEVELOPMENT environment\n",
    "dev_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"dev\"}\n",
    ")\n",
    "\n",
    "print(\"\\nDevelopment Tables:\")\n",
    "for table in dev_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 2: Project-Based Configuration\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 2: Project-Based Configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "queries_with_project = {\n",
    "    \"staging\": \"\"\"\n",
    "        CREATE TABLE {{project}}.staging.user_data AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            email,\n",
    "            created_at\n",
    "        FROM {{project}}.raw.users\n",
    "    \"\"\",\n",
    "    \"analytics\": \"\"\"\n",
    "        CREATE TABLE {{project}}.analytics.user_summary AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            COUNT(*) as activity_count\n",
    "        FROM {{project}}.staging.user_data\n",
    "        JOIN {{project}}.raw.activities USING (user_id)\n",
    "        GROUP BY user_id, username\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "pipeline = Pipeline.from_dict(\n",
    "    queries_with_project, dialect=\"bigquery\", template_context={\"project\": \"my_company\"}\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 3: Nested Variables\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 3: Nested Variables (config.property)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "queries_nested = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{config.project}}.{{config.env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount\n",
    "    FROM {{config.source_db}}.raw_{{config.region}}.orders\n",
    "    WHERE created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_nested = Pipeline.from_sql_list(\n",
    "    queries_nested,\n",
    "    dialect=\"bigquery\",\n",
    "    template_context={\n",
    "        \"config\": {\n",
    "            \"project\": \"data_platform\",\n",
    "            \"env\": \"staging\",\n",
    "            \"source_db\": \"external_db\",\n",
    "            \"region\": \"us_central\",\n",
    "            \"start_date\": \"2025-01-01\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline_nested.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 4: YAML Configuration (as you'd use in CLI)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 4: YAML-style Configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# YAML config file content\n",
    "yaml_config = \"\"\"\n",
    "env: production\n",
    "project: analytics_pipeline\n",
    "config:\n",
    "  region: us-central1\n",
    "  dataset: customer_data\n",
    "  start_date: 2025-01-01\n",
    "\"\"\"\n",
    "\n",
    "# Parse YAML\n",
    "template_context = yaml.safe_load(yaml_config)\n",
    "\n",
    "queries_yaml = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{project}}.{{env}}_staging.customers AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        region\n",
    "    FROM source.customers\n",
    "    WHERE region = '{{config.region}}'\n",
    "    AND created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_yaml = Pipeline.from_sql_list(\n",
    "    queries_yaml, dialect=\"bigquery\", template_context=template_context\n",
    ")\n",
    "\n",
    "print(\"\\nYAML Config:\")\n",
    "print(yaml.dump(template_context, default_flow_style=False))\n",
    "\n",
    "print(\"Generated Tables:\")\n",
    "for table in pipeline_yaml.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Example 5: Column Lineage with Templates\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 5: Column Lineage Tracing with Templates\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use the production pipeline from Example 1\n",
    "print(\"\\nTracing column lineage for: prod_analytics.customer_metrics.total_revenue\")\n",
    "\n",
    "# Trace column backward to sources\n",
    "sources = prod_pipeline.trace_column_backward(\"prod_analytics.customer_metrics\", \"total_revenue\")\n",
    "\n",
    "print(f\"\\nSource columns ({len(sources)}):\")\n",
    "for source in sources:\n",
    "    print(f\"  - {source.table_name}.{source.column_name} ({source.node_type})\")\n",
    "\n",
    "# Example 6: Without Template Context (preserves template syntax)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 6: Without Template Context (SQL validation only)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pipeline_no_context = Pipeline.from_sql_list(\n",
    "    queries_with_env,\n",
    "    dialect=\"bigquery\",\n",
    "    # NO template_context provided\n",
    ")\n",
    "\n",
    "print(\"\\nTables (template syntax preserved):\")\n",
    "for table in pipeline_no_context.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "print(\"\\nNote: Template syntax like {{env}} is preserved when no template_context is provided.\")\n",
    "print(\"This is useful for SQL validation before deployment.\")\n",
    "\n",
    "# Example 7: dbt-style ref() functions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Example 7: dbt-style ref() Functions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dbt_queries = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{ ref('staging_orders') }} AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount\n",
    "    FROM {{ ref('raw_orders') }}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "# Custom function to resolve dbt ref()\n",
    "def resolve_dbt_ref(table_name):\n",
    "    return f\"my_project.{table_name}\"\n",
    "\n",
    "\n",
    "# Manually resolve refs (for demonstration)\n",
    "# In practice, you'd use dbt's built-in templating\n",
    "pipeline_dbt = Pipeline.from_sql_list(\n",
    "    dbt_queries,\n",
    "    dialect=\"bigquery\",\n",
    "    template_context={\n",
    "        \"ref\": lambda name: f\"my_project.{name}\"  # Note: This won't work with Jinja2, just for demo\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nNote: For full dbt integration, use dbt's compiled SQL output\")\n",
    "print(\"or implement a custom Jinja2 function resolver.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Template Variables are Powerful!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "âœ… Use Cases:\n",
    "  - Multi-environment deployments (dev/staging/prod)\n",
    "  - Parameterized table names across regions/projects\n",
    "  - dbt integration (via compiled SQL)\n",
    "  - Airflow macro substitution\n",
    "  - CI/CD pipeline configuration\n",
    "\n",
    "âœ… Supported Syntaxes:\n",
    "  - Jinja2: {{ variable }}\n",
    "  - Nested: {{ config.property }}\n",
    "  - Functions: {{ ref('table') }} (with custom resolution)\n",
    "\n",
    "âœ… Input Formats:\n",
    "  - Python dict: {\"env\": \"prod\"}\n",
    "  - YAML: env: prod\n",
    "  - JSON: {\"env\": \"prod\"}\n",
    "\n",
    "ðŸ’¡ Best Practice:\n",
    "  - Define template variables in separate config files (YAML/JSON)\n",
    "  - Use consistent naming conventions (env, project, region)\n",
    "  - Document required variables in README\n",
    "  - Validate templates without context for syntax checking\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e446c27",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3a5215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.760242Z",
     "iopub.status.busy": "2025-12-30T20:02:28.760128Z",
     "iopub.status.idle": "2025-12-30T20:02:28.761866Z",
     "shell.execute_reply": "2025-12-30T20:02:28.761529Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from clgraph import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941219c6",
   "metadata": {},
   "source": [
    "### Example 1: Multi-Environment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe104f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.763230Z",
     "iopub.status.busy": "2025-12-30T20:02:28.763146Z",
     "iopub.status.idle": "2025-12-30T20:02:28.773416Z",
     "shell.execute_reply": "2025-12-30T20:02:28.773030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Multi-Environment Pipeline\n",
      "\n",
      "Production Tables:\n",
      "  - prod_staging.orders\n",
      "  - raw.orders\n",
      "  - prod_analytics.customer_metrics\n",
      "\n",
      "Development Tables:\n",
      "  - dev_staging.orders\n",
      "  - raw.orders\n",
      "  - dev_analytics.customer_metrics\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 1: Multi-Environment Pipeline\")\n",
    "\n",
    "# SQL with environment placeholders\n",
    "queries_with_env = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        order_date\n",
    "    FROM raw.orders\n",
    "    WHERE status = 'completed'\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{env}}_analytics.customer_metrics AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(amount) as total_revenue,\n",
    "        AVG(amount) as avg_order_value\n",
    "    FROM {{env}}_staging.orders\n",
    "    GROUP BY customer_id\n",
    "    \"\"\",\n",
    "]\n",
    "\n",
    "# Build pipeline for PRODUCTION environment\n",
    "prod_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"prod\"}\n",
    ")\n",
    "\n",
    "print(\"\\nProduction Tables:\")\n",
    "for table in prod_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "# Build pipeline for DEVELOPMENT environment\n",
    "dev_pipeline = Pipeline.from_sql_list(\n",
    "    queries_with_env, dialect=\"bigquery\", template_context={\"env\": \"dev\"}\n",
    ")\n",
    "\n",
    "print(\"\\nDevelopment Tables:\")\n",
    "for table in dev_pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4525339",
   "metadata": {},
   "source": [
    "### Example 2: Project-Based Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be3ac20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.775148Z",
     "iopub.status.busy": "2025-12-30T20:02:28.774967Z",
     "iopub.status.idle": "2025-12-30T20:02:28.781035Z",
     "shell.execute_reply": "2025-12-30T20:02:28.780694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'user_id' in expression for 'user_id'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query 'analytics': [unqualified_column] Unqualified column 'username' in expression for 'username'. With multiple tables (user_data, activities), the source table is ambiguous.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2: Project-Based Configuration\n",
      "\n",
      "Generated Tables:\n",
      "  - my_company.staging.user_data\n",
      "  - my_company.raw.users\n",
      "  - my_company.analytics.user_summary\n",
      "  - my_company.raw.activities\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 2: Project-Based Configuration\")\n",
    "\n",
    "queries_with_project = {\n",
    "    \"staging\": \"\"\"\n",
    "        CREATE TABLE {{project}}.staging.user_data AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            email,\n",
    "            created_at\n",
    "        FROM {{project}}.raw.users\n",
    "    \"\"\",\n",
    "    \"analytics\": \"\"\"\n",
    "        CREATE TABLE {{project}}.analytics.user_summary AS\n",
    "        SELECT\n",
    "            user_id,\n",
    "            username,\n",
    "            COUNT(*) as activity_count\n",
    "        FROM {{project}}.staging.user_data\n",
    "        JOIN {{project}}.raw.activities USING (user_id)\n",
    "        GROUP BY user_id, username\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "pipeline = Pipeline.from_dict(\n",
    "    queries_with_project, dialect=\"bigquery\", template_context={\"project\": \"my_company\"}\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd136b",
   "metadata": {},
   "source": [
    "### Example 3: Nested Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea242d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.782926Z",
     "iopub.status.busy": "2025-12-30T20:02:28.782794Z",
     "iopub.status.idle": "2025-12-30T20:02:28.787658Z",
     "shell.execute_reply": "2025-12-30T20:02:28.787262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3: Nested Variables (config.property)\n",
      "\n",
      "Generated Tables:\n",
      "  - data_platform.staging_staging.orders\n",
      "  - external_db.raw_us_central.orders\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 3: Nested Variables (config.property)\")\n",
    "\n",
    "queries_nested = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{config.project}}.{{config.env}}_staging.orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount\n",
    "    FROM {{config.source_db}}.raw_{{config.region}}.orders\n",
    "    WHERE created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_nested = Pipeline.from_sql_list(\n",
    "    queries_nested,\n",
    "    dialect=\"bigquery\",\n",
    "    template_context={\n",
    "        \"config\": {\n",
    "            \"project\": \"data_platform\",\n",
    "            \"env\": \"staging\",\n",
    "            \"source_db\": \"external_db\",\n",
    "            \"region\": \"us_central\",\n",
    "            \"start_date\": \"2025-01-01\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nGenerated Tables:\")\n",
    "for table in pipeline_nested.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f76de2",
   "metadata": {},
   "source": [
    "### Example 4: YAML Configuration (as you'd use in CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebbb946e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.788696Z",
     "iopub.status.busy": "2025-12-30T20:02:28.788624Z",
     "iopub.status.idle": "2025-12-30T20:02:28.794048Z",
     "shell.execute_reply": "2025-12-30T20:02:28.793678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 4: YAML-style Configuration\n",
      "\n",
      "YAML Config:\n",
      "config:\n",
      "  dataset: customer_data\n",
      "  region: us-central1\n",
      "  start_date: 2025-01-01\n",
      "env: production\n",
      "project: analytics_pipeline\n",
      "\n",
      "Generated Tables:\n",
      "  - analytics_pipeline.production_staging.customers\n",
      "  - source.customers\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 4: YAML-style Configuration\")\n",
    "\n",
    "# YAML config file content\n",
    "yaml_config = \"\"\"\n",
    "env: production\n",
    "project: analytics_pipeline\n",
    "config:\n",
    "  region: us-central1\n",
    "  dataset: customer_data\n",
    "  start_date: 2025-01-01\n",
    "\"\"\"\n",
    "\n",
    "# Parse YAML\n",
    "template_context = yaml.safe_load(yaml_config)\n",
    "\n",
    "queries_yaml = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{project}}.{{env}}_staging.customers AS\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        region\n",
    "    FROM source.customers\n",
    "    WHERE region = '{{config.region}}'\n",
    "    AND created_at >= '{{config.start_date}}'\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline_yaml = Pipeline.from_sql_list(\n",
    "    queries_yaml, dialect=\"bigquery\", template_context=template_context\n",
    ")\n",
    "\n",
    "print(\"\\nYAML Config:\")\n",
    "print(yaml.dump(template_context, default_flow_style=False))\n",
    "\n",
    "print(\"Generated Tables:\")\n",
    "for table in pipeline_yaml.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12788f18",
   "metadata": {},
   "source": [
    "### Example 5: Column Lineage with Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c2d885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.795183Z",
     "iopub.status.busy": "2025-12-30T20:02:28.795105Z",
     "iopub.status.idle": "2025-12-30T20:02:28.799537Z",
     "shell.execute_reply": "2025-12-30T20:02:28.798649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 5: Column Lineage Tracing with Templates\n",
      "\n",
      "Tracing column lineage for: prod_analytics.customer_metrics.total_revenue\n",
      "\n",
      "Source columns (1):\n",
      "  - raw.orders.amount (base_column)\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 5: Column Lineage Tracing with Templates\")\n",
    "\n",
    "# Use the production pipeline from Example 1\n",
    "print(\"\\nTracing column lineage for: prod_analytics.customer_metrics.total_revenue\")\n",
    "\n",
    "# Trace column backward to sources\n",
    "sources = prod_pipeline.trace_column_backward(\"prod_analytics.customer_metrics\", \"total_revenue\")\n",
    "\n",
    "print(f\"\\nSource columns ({len(sources)}):\")\n",
    "for source in sources:\n",
    "    print(f\"  - {source.table_name}.{source.column_name} ({source.node_type})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tjmhy9xgu4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.800776Z",
     "iopub.status.busy": "2025-12-30T20:02:28.800669Z",
     "iopub.status.idle": "2025-12-30T20:02:28.973225Z",
     "shell.execute_reply": "2025-12-30T20:02:28.972746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production Pipeline Column Lineage:\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/backend/execute.py:76\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = subprocess.PIPE\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     proc = \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/backend/execute.py:96\u001b[39m, in \u001b[36m_run_input_lines\u001b[39m\u001b[34m(cmd, input_lines, kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_input_lines\u001b[39m(cmd, input_lines, *, kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     popen = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     stdin_write = popen.stdin.write\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.0-macos-aarch64-none/lib/python3.13/subprocess.py:1036\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1033\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1034\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.0-macos-aarch64-none/lib/python3.13/subprocess.py:1966\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1966\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1967\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mExecutableNotFound\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/IPython/core/formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/jupyter_integration.py:98\u001b[39m, in \u001b[36mJupyterIntegration._repr_mimebundle_\u001b[39m\u001b[34m(self, include, exclude, **_)\u001b[39m\n\u001b[32m     96\u001b[39m include = \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m._jupyter_mimetype}\n\u001b[32m     97\u001b[39m include -= \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES.items()\n\u001b[32m    100\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/jupyter_integration.py:112\u001b[39m, in \u001b[36mJupyterIntegration._repr_image_svg_xml\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_image_svg_xml\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msvg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSVG_ENCODING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/piping.py:104\u001b[39m, in \u001b[36mPipe.pipe\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m     56\u001b[39m          \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     57\u001b[39m          renderer: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m          engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     62\u001b[39m          encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \u001b[33;03m        '<?xml version='\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/_tools.py:185\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     wanted = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    178\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated.items())\n\u001b[32m    179\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m will be reduced\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    180\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m positional arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mqualification\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as keyword arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    182\u001b[39m                   stacklevel=stacklevel,\n\u001b[32m    183\u001b[39m                   category=category)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/piping.py:121\u001b[39m, in \u001b[36mPipe._pipe_legacy\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@_tools\u001b[39m.deprecate_positional_args(supported_number=\u001b[32m1\u001b[39m, ignore_arg=\u001b[33m'\u001b[39m\u001b[33mself\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    114\u001b[39m                  \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m                  engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    120\u001b[39m                  encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/piping.py:149\u001b[39m, in \u001b[36mPipe._pipe_future\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m codecs.lookup(encoding) \u001b[38;5;129;01mis\u001b[39;00m codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding):\n\u001b[32m    148\u001b[39m         \u001b[38;5;66;03m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_lines_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    151\u001b[39m         raw = \u001b[38;5;28mself\u001b[39m._pipe_lines(*args, input_encoding=\u001b[38;5;28mself\u001b[39m.encoding, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/backend/piping.py:212\u001b[39m, in \u001b[36mpipe_lines_string\u001b[39m\u001b[34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[39m\n\u001b[32m    206\u001b[39m cmd = dot_command.command(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[32m    207\u001b[39m                           renderer=renderer,\n\u001b[32m    208\u001b[39m                           formatter=formatter,\n\u001b[32m    209\u001b[39m                           neato_no_op=neato_no_op)\n\u001b[32m    210\u001b[39m kwargs = {\u001b[33m'\u001b[39m\u001b[33minput_lines\u001b[39m\u001b[33m'\u001b[39m: input_lines, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m: encoding}\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m proc = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proc.stdout\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/clpipe/clgraph/.venv/lib/python3.13/site-packages/graphviz/backend/execute.py:81\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno == errno.ENOENT:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc.stderr:\n",
      "\u001b[31mExecutableNotFound\u001b[39m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x10adcea50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clgraph import visualize_pipeline_lineage\n",
    "\n",
    "# Visualize the production pipeline lineage\n",
    "print(\"Production Pipeline Column Lineage:\")\n",
    "visualize_pipeline_lineage(prod_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28259b50",
   "metadata": {},
   "source": [
    "### Example 6: Without Template Context (preserves template syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc39482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.975171Z",
     "iopub.status.busy": "2025-12-30T20:02:28.975040Z",
     "iopub.status.idle": "2025-12-30T20:02:28.981152Z",
     "shell.execute_reply": "2025-12-30T20:02:28.980747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 6: Without Template Context (SQL validation only)\n",
      "\n",
      "Tables (template syntax preserved):\n",
      "  - {{env}}_staging.orders\n",
      "  - raw.orders\n",
      "  - {{env}}_analytics.customer_metrics\n",
      "\n",
      "Note: Template syntax like {{env}} is preserved when no template_context is provided.\n",
      "This is useful for SQL validation before deployment.\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 6: Without Template Context (SQL validation only)\")\n",
    "\n",
    "pipeline_no_context = Pipeline.from_sql_list(\n",
    "    queries_with_env,\n",
    "    dialect=\"bigquery\",\n",
    "    # NO template_context provided\n",
    ")\n",
    "\n",
    "print(\"\\nTables (template syntax preserved):\")\n",
    "for table in pipeline_no_context.table_graph.tables.keys():\n",
    "    print(f\"  - {table}\")\n",
    "\n",
    "print(\"\\nNote: Template syntax like {{env}} is preserved when no template_context is provided.\")\n",
    "print(\"This is useful for SQL validation before deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60025c53",
   "metadata": {},
   "source": [
    "### Example 7: dbt-style ref() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b563b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T20:02:28.982611Z",
     "iopub.status.busy": "2025-12-30T20:02:28.982348Z",
     "iopub.status.idle": "2025-12-30T20:02:28.987080Z",
     "shell.execute_reply": "2025-12-30T20:02:28.986691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 7: dbt-style ref() Functions\n",
      "\n",
      "Note: For full dbt integration, use dbt's compiled SQL output\n",
      "or implement a custom Jinja2 function resolver.\n",
      "Summary: Template Variables are Powerful!\n",
      "\n",
      "âœ… Use Cases:\n",
      "  - Multi-environment deployments (dev/staging/prod)\n",
      "  - Parameterized table names across regions/projects\n",
      "  - dbt integration (via compiled SQL)\n",
      "  - Airflow macro substitution\n",
      "  - CI/CD pipeline configuration\n",
      "\n",
      "âœ… Supported Syntaxes:\n",
      "  - Jinja2: {{ variable }}\n",
      "  - Nested: {{ config.property }}\n",
      "  - Functions: {{ ref('table') }} (with custom resolution)\n",
      "\n",
      "âœ… Input Formats:\n",
      "  - Python dict: {\"env\": \"prod\"}\n",
      "  - YAML: env: prod\n",
      "  - JSON: {\"env\": \"prod\"}\n",
      "\n",
      "ðŸ’¡ Best Practice:\n",
      "  - Define template variables in separate config files (YAML/JSON)\n",
      "  - Use consistent naming conventions (env, project, region)\n",
      "  - Document required variables in README\n",
      "  - Validate templates without context for syntax checking\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 7: dbt-style ref() Functions\")\n",
    "\n",
    "dbt_queries = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE {{ ref('staging_orders') }} AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount\n",
    "    FROM {{ ref('raw_orders') }}\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "\n",
    "# Note: resolve_dbt_ref is already defined in a previous cell\n",
    "# Manually resolve refs (for demonstration)\n",
    "# In practice, you'd use dbt's built-in templating\n",
    "pipeline_dbt = Pipeline.from_sql_list(\n",
    "    dbt_queries,\n",
    "    dialect=\"bigquery\",\n",
    "    template_context={\n",
    "        \"ref\": lambda name: f\"my_project.{name}\"  # Note: This won't work with Jinja2, just for demo\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"\\nNote: For full dbt integration, use dbt's compiled SQL output\")\n",
    "print(\"or implement a custom Jinja2 function resolver.\")\n",
    "\n",
    "print(\"Summary: Template Variables are Powerful!\")\n",
    "print(\"\"\"\n",
    "âœ… Use Cases:\n",
    "  - Multi-environment deployments (dev/staging/prod)\n",
    "  - Parameterized table names across regions/projects\n",
    "  - dbt integration (via compiled SQL)\n",
    "  - Airflow macro substitution\n",
    "  - CI/CD pipeline configuration\n",
    "\n",
    "âœ… Supported Syntaxes:\n",
    "  - Jinja2: {{ variable }}\n",
    "  - Nested: {{ config.property }}\n",
    "  - Functions: {{ ref('table') }} (with custom resolution)\n",
    "\n",
    "âœ… Input Formats:\n",
    "  - Python dict: {\"env\": \"prod\"}\n",
    "  - YAML: env: prod\n",
    "  - JSON: {\"env\": \"prod\"}\n",
    "\n",
    "ðŸ’¡ Best Practice:\n",
    "  - Define template variables in separate config files (YAML/JSON)\n",
    "  - Use consistent naming conventions (env, project, region)\n",
    "  - Document required variables in README\n",
    "  - Validate templates without context for syntax checking\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
