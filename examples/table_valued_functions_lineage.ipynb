{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44b0bcd",
   "metadata": {},
   "source": [
    "# Table Valued Functions Lineage\n",
    "\n",
    "**Example: Table-Valued Functions (TVF) Support for Column Lineage**\n",
    "\n",
    "\n",
    "Demonstrates how clgraph tracks column lineage through Table-Valued Functions:\n",
    "- Generator TVFs (GENERATE_SERIES, GENERATE_DATE_ARRAY)\n",
    "- External data TVFs (READ_CSV)\n",
    "- Synthetic column marking\n",
    "- TVF parameters in lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27d96b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f0f271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:03.228582Z",
     "iopub.status.busy": "2025-12-30T19:34:03.228469Z",
     "iopub.status.idle": "2025-12-30T19:34:03.279984Z",
     "shell.execute_reply": "2025-12-30T19:34:03.279537Z"
    }
   },
   "outputs": [],
   "source": [
    "from clgraph import JSONExporter, Pipeline, RecursiveLineageBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1da968",
   "metadata": {},
   "source": [
    "### Example 1: GENERATE_SERIES (PostgreSQL/DuckDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320bc34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:03.281317Z",
     "iopub.status.busy": "2025-12-30T19:34:03.281235Z",
     "iopub.status.idle": "2025-12-30T19:34:03.286479Z",
     "shell.execute_reply": "2025-12-30T19:34:03.286082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: GENERATE_SERIES - Generator TVF\n",
      "\n",
      "SQL:\n",
      "\n",
      "SELECT num * 2 AS doubled\n",
      "FROM GENERATE_SERIES(1, 10) AS t(num)\n",
      "\n",
      "\n",
      "Column Lineage:\n",
      "  output.doubled\n",
      "  t.num [SYNTHETIC from generate_series]\n",
      "\n",
      "Edges:\n",
      "  t.num -> output.doubled [TVF output]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 1: GENERATE_SERIES - Generator TVF\")\n",
    "\n",
    "sql_generate_series = \"\"\"\n",
    "SELECT num * 2 AS doubled\n",
    "FROM GENERATE_SERIES(1, 10) AS t(num)\n",
    "\"\"\"\n",
    "\n",
    "builder = RecursiveLineageBuilder(sql_generate_series, dialect=\"postgres\")\n",
    "graph = builder.build()\n",
    "\n",
    "print(\"\\nSQL:\")\n",
    "print(sql_generate_series)\n",
    "\n",
    "print(\"\\nColumn Lineage:\")\n",
    "for name, node in graph.nodes.items():\n",
    "    if node.is_synthetic:\n",
    "        print(f\"  {name} [SYNTHETIC from {node.synthetic_source}]\")\n",
    "    else:\n",
    "        print(f\"  {name}\")\n",
    "\n",
    "print(\"\\nEdges:\")\n",
    "for edge in graph.edges:\n",
    "    tvf_marker = \" [TVF output]\" if edge.is_tvf_output else \"\"\n",
    "    print(f\"  {edge.from_node.full_name} -> {edge.to_node.full_name}{tvf_marker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a96ffd",
   "metadata": {},
   "source": [
    "### Example 2: Multiple TVFs in JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d95e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:03.287426Z",
     "iopub.status.busy": "2025-12-30T19:34:03.287345Z",
     "iopub.status.idle": "2025-12-30T19:34:03.290367Z",
     "shell.execute_reply": "2025-12-30T19:34:03.289829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2: Multiple TVFs with JOIN\n",
      "\n",
      "SQL:\n",
      "\n",
      "SELECT\n",
      "    d.num AS day_num,\n",
      "    h.num AS hour_num\n",
      "FROM GENERATE_SERIES(1, 31) AS d(num)\n",
      "CROSS JOIN GENERATE_SERIES(0, 23) AS h(num)\n",
      "\n",
      "\n",
      "Synthetic columns from TVFs:\n",
      "  d.num: generated by generate_series\n",
      "  h.num: generated by generate_series\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 2: Multiple TVFs with JOIN\")\n",
    "\n",
    "sql_multi_tvf = \"\"\"\n",
    "SELECT\n",
    "    d.num AS day_num,\n",
    "    h.num AS hour_num\n",
    "FROM GENERATE_SERIES(1, 31) AS d(num)\n",
    "CROSS JOIN GENERATE_SERIES(0, 23) AS h(num)\n",
    "\"\"\"\n",
    "\n",
    "builder2 = RecursiveLineageBuilder(sql_multi_tvf, dialect=\"postgres\")\n",
    "graph2 = builder2.build()\n",
    "\n",
    "print(\"\\nSQL:\")\n",
    "print(sql_multi_tvf)\n",
    "\n",
    "print(\"\\nSynthetic columns from TVFs:\")\n",
    "for name, node in graph2.nodes.items():\n",
    "    if node.is_synthetic:\n",
    "        print(f\"  {name}: generated by {node.synthetic_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e1256",
   "metadata": {},
   "source": [
    "### Example 3: TVF in Pipeline with CREATE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57dace84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:03.291401Z",
     "iopub.status.busy": "2025-12-30T19:34:03.291331Z",
     "iopub.status.idle": "2025-12-30T19:34:03.294530Z",
     "shell.execute_reply": "2025-12-30T19:34:03.294196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3: TVF in Pipeline\n",
      "\n",
      "SQL:\n",
      "\n",
      "CREATE TABLE date_range AS\n",
      "SELECT num AS day_number\n",
      "FROM GENERATE_SERIES(1, 365) AS t(num)\n",
      "\n",
      "\n",
      "Pipeline columns:\n",
      "  date_range.day_number\n",
      "  create_dates:unknown.num [from generate_series]\n",
      "\n",
      "Pipeline edges:\n",
      "  create_dates:unknown.num -> date_range.day_number [tvf_output]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 3: TVF in Pipeline\")\n",
    "\n",
    "sql_pipeline = \"\"\"\n",
    "CREATE TABLE date_range AS\n",
    "SELECT num AS day_number\n",
    "FROM GENERATE_SERIES(1, 365) AS t(num)\n",
    "\"\"\"\n",
    "\n",
    "pipeline = Pipeline([(\"create_dates\", sql_pipeline)], dialect=\"postgres\")\n",
    "\n",
    "print(\"\\nSQL:\")\n",
    "print(sql_pipeline)\n",
    "\n",
    "print(\"\\nPipeline columns:\")\n",
    "for name, col in pipeline.column_graph.columns.items():\n",
    "    synth = f\" [from {col.synthetic_source}]\" if col.is_synthetic else \"\"\n",
    "    print(f\"  {name}{synth}\")\n",
    "\n",
    "print(\"\\nPipeline edges:\")\n",
    "for edge in pipeline.column_graph.edges:\n",
    "    print(f\"  {edge.from_node.full_name} -> {edge.to_node.full_name} [{edge.edge_type}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00c142",
   "metadata": {},
   "source": [
    "### Example 4: JSON Export with TVF metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6873c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:03.295610Z",
     "iopub.status.busy": "2025-12-30T19:34:03.295530Z",
     "iopub.status.idle": "2025-12-30T19:34:03.298112Z",
     "shell.execute_reply": "2025-12-30T19:34:03.297481Z"
    }
   },
   "outputs": [],
   "source": "import json\n\nprint(\"Example 4: JSON Export with TVF Metadata\")\n\nexporter = JSONExporter()\nexport_data = exporter.export(pipeline)\n\nprint(\"\\nExported columns with synthetic info:\")\nfor col in export_data.get(\"columns\", []):\n    if col.get(\"is_synthetic\"):\n        print(json.dumps(col, indent=2))\n\nprint(\"\\nExported edges with TVF info:\")\nfor edge in export_data.get(\"edges\", []):\n    if edge.get(\"is_tvf_output\"):\n        print(json.dumps(edge, indent=2))\n        break"
  },
  {
   "cell_type": "markdown",
   "id": "e133c6e4",
   "metadata": {},
   "source": [
    "### Example 5: READ_CSV (DuckDB) - External TVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30904ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T19:34:03.299393Z",
     "iopub.status.busy": "2025-12-30T19:34:03.299291Z",
     "iopub.status.idle": "2025-12-30T19:34:03.305592Z",
     "shell.execute_reply": "2025-12-30T19:34:03.305224Z"
    }
   },
   "outputs": [],
   "source": "from clgraph.query_parser import RecursiveQueryParser\n\nprint(\"Example 5: READ_CSV - External Data TVF\")\n\nsql_read_csv = \"\"\"\nSELECT *\nFROM READ_CSV('s3://bucket/data.csv') AS t\n\"\"\"\n\nparser = RecursiveQueryParser(sql_read_csv, dialect=\"duckdb\")\nunit_graph = parser.parse()\n\nprint(\"\\nSQL:\")\nprint(sql_read_csv)\n\nprint(\"\\nTVF sources detected:\")\nfor unit in unit_graph.units.values():\n    for alias, tvf in unit.tvf_sources.items():\n        print(f\"  {alias}: {tvf.function_name} ({tvf.tvf_type.value})\")\n        if tvf.external_source:\n            print(f\"    External source: {tvf.external_source}\")\n\n# Summary\nprint(\"Summary\")\nprint(\n    \"\"\"\ne-Valued Functions support captures:\nnerator TVFs (GENERATE_SERIES, GENERATE_DATE_ARRAY)\nternal data TVFs (READ_CSV, READ_PARQUET)\nlumn aliases from TVF AS t(col1, col2) syntax\nF parameters (start, end, step values)\nternal source paths for file-reading TVFs\n\nhetic columns are marked with:\n_synthetic: True\nnthetic_source: function name (e.g., \"generate_series\")\nf_parameters: parameter dictionary\n\n metadata is preserved through:\ncursiveLineageBuilder (single query analysis)\npeline (multi-query analysis)\nON export\n\"\"\"\n)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}