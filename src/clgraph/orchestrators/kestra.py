"""
Kestra orchestrator integration for clgraph.

Converts clgraph pipelines to Kestra YAML flows.
Kestra is a declarative orchestration platform using YAML-based workflow definitions.
"""

from typing import TYPE_CHECKING, Any, Dict, Optional

import yaml

from .base import BaseOrchestrator

if TYPE_CHECKING:
    pass


class KestraOrchestrator(BaseOrchestrator):
    """
    Converts clgraph pipelines to Kestra YAML flows.

    Kestra uses YAML-based workflow definitions with tasks that can have
    dependencies via the `dependsOn` field.

    Example:
        from clgraph.orchestrators import KestraOrchestrator

        orchestrator = KestraOrchestrator(pipeline)
        yaml_content = orchestrator.to_flow(
            flow_id="my_pipeline",
            namespace="clgraph.production",
        )

        # Save to file
        with open("flows/my_pipeline.yml", "w") as f:
            f.write(yaml_content)
    """

    def to_flow(
        self,
        flow_id: str,
        namespace: str,
        description: Optional[str] = None,
        connection_config: Optional[Dict[str, str]] = None,
        retry_attempts: int = 3,
        retry_delay: str = "PT1M",
        labels: Optional[Dict[str, str]] = None,
        **kwargs,
    ) -> str:
        """
        Generate Kestra flow YAML from pipeline.

        Args:
            flow_id: Unique identifier for the flow
            namespace: Kestra namespace (e.g., "clgraph.production")
            description: Optional flow description (auto-generated if not provided)
            connection_config: Database connection config:
                {
                    "url": "jdbc:clickhouse://host:port/db",
                    "username": "default",
                    "password": ""
                }
            retry_attempts: Number of retry attempts (default: 3)
            retry_delay: ISO 8601 duration between retries (default: PT1M)
            labels: Optional key-value labels for flow
            **kwargs: Additional flow-level configuration

        Returns:
            YAML string representing Kestra flow

        Examples:
            # Basic usage
            yaml_content = orchestrator.to_flow(
                flow_id="my_pipeline",
                namespace="clgraph.production"
            )

            # With custom connection and schedule
            yaml_content = orchestrator.to_flow(
                flow_id="daily_analytics",
                namespace="clgraph.analytics",
                connection_config={
                    "url": "jdbc:clickhouse://localhost:8123/default",
                    "username": "default",
                    "password": "",
                },
                labels={"env": "production", "team": "analytics"},
            )

        Note:
            - Use to_flow_with_triggers() to add scheduling
            - Tasks use io.kestra.plugin.jdbc.clickhouse.Query type
            - Dependencies are managed via dependsOn field
        """
        table_graph = self.table_graph

        # Auto-generate description
        if description is None:
            query_count = len(table_graph.queries)
            table_count = len(table_graph.tables)
            description = (
                f"Pipeline with {query_count} queries operating on "
                f"{table_count} tables. Generated by clgraph."
            )

        # Default connection config
        if connection_config is None:
            connection_config = {
                "url": "jdbc:clickhouse://clickhouse:8123/default",
                "username": "default",
                "password": "",
            }

        # Build tasks list
        tasks = []
        task_id_mapping: Dict[str, str] = {}  # query_id -> task_id

        for query_id in table_graph.topological_sort():
            query = table_graph.queries[query_id]
            task_id = self._sanitize_name(query_id)
            task_id_mapping[query_id] = task_id

            # Find dependencies
            depends_on = []
            for source_table in query.source_tables:
                if source_table in table_graph.tables:
                    table_node = table_graph.tables[source_table]
                    if table_node.created_by and table_node.created_by in task_id_mapping:
                        depends_on.append(task_id_mapping[table_node.created_by])

            task: Dict[str, Any] = {
                "id": task_id,
                "type": "io.kestra.plugin.jdbc.clickhouse.Query",
                "url": connection_config["url"],
                "username": connection_config["username"],
                "password": connection_config["password"],
                "sql": query.sql,
                "retry": {
                    "type": "constant",
                    "maxAttempt": retry_attempts,
                    "interval": retry_delay,
                },
            }

            if depends_on:
                task["dependsOn"] = depends_on

            tasks.append(task)

        # Build flow structure
        flow: Dict[str, Any] = {
            "id": flow_id,
            "namespace": namespace,
            "description": description,
            "labels": labels or {"generator": "clgraph"},
            "tasks": tasks,
        }

        # Add any additional kwargs
        flow.update(kwargs)

        return yaml.dump(flow, default_flow_style=False, sort_keys=False)

    def to_flow_with_triggers(
        self,
        flow_id: str,
        namespace: str,
        cron: Optional[str] = None,
        **kwargs,
    ) -> str:
        """
        Generate Kestra flow YAML with schedule triggers.

        Args:
            flow_id: Unique identifier for the flow
            namespace: Kestra namespace
            cron: Cron expression for scheduling (e.g., "0 0 * * *" for daily)
            **kwargs: Additional arguments passed to to_flow()

        Returns:
            YAML string with triggers configured

        Examples:
            # Daily at midnight
            yaml_content = orchestrator.to_flow_with_triggers(
                flow_id="daily_pipeline",
                namespace="clgraph.production",
                cron="0 0 * * *"
            )

            # Every hour
            yaml_content = orchestrator.to_flow_with_triggers(
                flow_id="hourly_pipeline",
                namespace="clgraph.production",
                cron="0 * * * *"
            )
        """
        flow_yaml = self.to_flow(flow_id=flow_id, namespace=namespace, **kwargs)
        flow_dict = yaml.safe_load(flow_yaml)

        if cron:
            flow_dict["triggers"] = [
                {
                    "id": "schedule",
                    "type": "io.kestra.plugin.core.trigger.Schedule",
                    "cron": cron,
                }
            ]

        return yaml.dump(flow_dict, default_flow_style=False, sort_keys=False)

    def to_flow_dict(
        self,
        flow_id: str,
        namespace: str,
        **kwargs,
    ) -> Dict[str, Any]:
        """
        Generate Kestra flow as a Python dictionary.

        Useful when you need to manipulate the flow structure programmatically
        before serializing to YAML.

        Args:
            flow_id: Unique identifier for the flow
            namespace: Kestra namespace
            **kwargs: Additional arguments passed to to_flow()

        Returns:
            Dictionary representing Kestra flow structure
        """
        yaml_content = self.to_flow(flow_id=flow_id, namespace=namespace, **kwargs)
        return yaml.safe_load(yaml_content)


__all__ = ["KestraOrchestrator"]
